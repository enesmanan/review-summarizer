import os
import time
import requests
import re

import pandas as pd
import plotly.express as px
import streamlit as st

#from scrape.trendyol_scraper import scrape_product_comments
from scripts.review_summarizer import analyze_reviews

if not os.path.exists("data"):
    os.makedirs("data")


st.set_page_config(page_title="Trendyol Yorum Analizi", layout="wide")


def create_sentiment_plot(df):
    """Creates a pie chart visualization for sentiment distribution"""
    sentiment_counts = df["sentiment_label"].value_counts()
    fig = px.pie(
        values=sentiment_counts.values,
        names=sentiment_counts.index,
        title="Duygu Analizi DaÄŸÄ±lÄ±mÄ±",
        color_discrete_map={
            "Pozitif": "#2ecc71",
            "NÃ¶tr": "#95a5a6",
            "Negatif": "#e74c3c",
        },
    )
    return fig


def create_star_plot(df):
    """Creates a bar chart visualization for star rating distribution"""
    star_counts = df["YÄ±ldÄ±z SayÄ±sÄ±"].value_counts().sort_index()
    fig = px.bar(
        x=star_counts.index,
        y=star_counts.values,
        title="YÄ±ldÄ±z DaÄŸÄ±lÄ±mÄ±",
        labels={"x": "YÄ±ldÄ±z SayÄ±sÄ±", "y": "Yorum SayÄ±sÄ±"},
        color_discrete_sequence=["#f39c12"],
    )
    fig.update_layout(
        xaxis=dict(
            tickmode="array",
            ticktext=["â­", "â­â­", "â­â­â­", "â­â­â­â­", "â­â­â­â­â­"],
        )
    )
    return fig


if "analysis_started" not in st.session_state:
    st.session_state.analysis_started = False

st.title("Trendyol Yorum Analizi")
st.markdown(
    """
Bu uygulama, Trendyol Ã¼rÃ¼n sayfasÄ±ndaki yorumlarÄ± analiz eder ve Ã¶zetler.

KullanÄ±m:
1. Trendyol Ã¼rÃ¼n yorumlar sayfasÄ±nÄ±n URL'sini girin
2. Gemini API anahtarÄ±nÄ±zÄ± girin
3. 'Analiz Et' butonuna tÄ±klayÄ±n
"""
)

with st.form("analysis_form"):
    url = st.text_input(
        "Trendyol ÃœrÃ¼n YorumlarÄ± URL",
        placeholder="Ã¼rÃ¼nÃ¼n linki",
    )
    api_key = st.text_input("Gemini API AnahtarÄ±", type="password")
    submitted = st.form_submit_button("Analiz Et")

if submitted and url and api_key:
    st.session_state.analysis_started = True

if st.session_state.analysis_started:
    try:
        progress_bar = st.progress(0)
        status_text = st.empty()

        status_text.text("Yorumlar Ã§ekiliyor...")
        progress_bar.progress(0.1)
        def scrape_product_comments_v2(url):
            headers = {
    "accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7",
    "accept-language": "en-US,en;q=0.9","cache-control": "max-age=0","upgrade-insecure-requests": "1",
    "user-agent": "Mozilla/5.0 (iPad; CPU OS 14_6_1 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) FxiOS/129.0 Mobile/15E148 Safari/605.1.15"}       
            # Regex ile product_id'yi alÄ±yoruz
            match = re.search(r"-p-(\d+)", url)
            if match:
                product_id = match.group(1)
                print(f"Product ID: {product_id}")
            else:
                print("Product ID not found.")
            # API URL'si oluÅŸturuluyor
            api_url = f"https://apigw.trendyol.com/discovery-web-websfxsocialreviewrating-santral/product-reviews-detailed?contentId={product_id}&page=1&order=DESC&orderBy=Score&channelId=1"
            # 3) YorumlarÄ± Ã§ekmek iÃ§in fonksiyon
            def fetch_reviews(api_url, headers):
                all_reviews = []
                try:
                # Ä°lk isteÄŸi yap ve totalPages deÄŸerini al
                    response = requests.get(api_url, headers=headers)
                    if response.status_code == 200:
                        data = response.json()
                        total_pages = data["result"]["productReviews"]["totalPages"]
                        print(f"Toplam Sayfa: {total_pages}")
            
                        # Ä°lk sayfadaki verileri ekle
                        all_reviews.extend(data["result"]["productReviews"]["content"])
            
                        # Kalan sayfalarÄ± dÃ¶ngÃ¼yle al
                        for page in range(2, total_pages + 1):
                            paginated_url = api_url.replace("page=1", f"page={page}")
                            response = requests.get(paginated_url, headers=headers)
                            if response.status_code == 200:
                                page_data = response.json()
                                all_reviews.extend(page_data["result"]["productReviews"]["content"])
                            else:
                                print(f"Sayfa {page} iÃ§in istek baÅŸarÄ±sÄ±z oldu: {response.status_code}")
        
                    else:
                        print(f"Ä°stek baÅŸarÄ±sÄ±z oldu: {response.status_code}")
                except Exception as e:
                    print(f"Bir hata oluÅŸtu: {e}")
    
                return all_reviews
            # YorumlarÄ± Ã§ek
            reviews = fetch_reviews(api_url, headers)
            # ArtÄ±k tÃ¼m yorumlar reviews listesinde yer alÄ±yor.

            # 4) YorumlarÄ± pandas DataFrame'e dÃ¶nÃ¼ÅŸtÃ¼rme
            reviews_df = pd.DataFrame(reviews)
            reviews_df = reviews_df.rename(columns={"id": "KullanÄ±cÄ±_id","userFullName": "KullanÄ±cÄ± AdÄ±","comment": "Yorum","lastModifiedDate": "Tarih","rate": "YÄ±ldÄ±z SayÄ±sÄ±"})
            reviews_df = reviews_df[["KullanÄ±cÄ±_id","KullanÄ±cÄ± AdÄ±","Yorum","Tarih","YÄ±ldÄ±z SayÄ±sÄ±"]]
            return reviews_df
        df = scrape_product_comments_v2(url)
        #df = scrape_product_comments(url)
        if df is None or len(df) == 0:
            st.error("Yorumlar Ã§ekilemedi. URL'yi kontrol edin.")
            st.session_state.analysis_started = False
        else:
            data_path = os.path.join("data", "product_comments.csv")
            df.to_csv(data_path, index=False, encoding="utf-8-sig")

            status_text.text("Yorumlar analiz ediliyor...")
            progress_bar.progress(0.4)
            summary, analyzed_df = analyze_reviews(data_path, api_key)

            status_text.text("SonuÃ§lar hazÄ±rlanÄ±yor...")
            progress_bar.progress(0.7)

            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("Toplam Yorum", len(df))
            with col2:
                st.metric("ÃœrÃ¼n DeÄŸerlendirme SayÄ±sÄ±", len(analyzed_df))
            with col3:
                st.metric(
                    "Ortalama Puan", f"{analyzed_df['YÄ±ldÄ±z SayÄ±sÄ±'].mean():.1f}â­"
                )
            with col4:
                positive_ratio = (
                    len(analyzed_df[analyzed_df["sentiment_label"] == "Pozitif"])
                    / len(analyzed_df)
                    * 100
                )
                st.metric("Olumlu Yorum OranÄ±", f"%{positive_ratio:.1f}")

            removed_reviews = len(df) - len(analyzed_df)
            if removed_reviews > 0:
                st.info(
                    f"Not: Toplam {removed_reviews} adet kargo, teslimat ve satÄ±cÄ± ile ilgili yorum analiz dÄ±ÅŸÄ± bÄ±rakÄ±lmÄ±ÅŸtÄ±r."
                )

            st.subheader("ğŸ“ Genel DeÄŸerlendirme")
            st.write(summary)

            col1, col2 = st.columns(2)
            with col1:
                st.plotly_chart(
                    create_sentiment_plot(analyzed_df), use_container_width=True
                )
            with col2:
                st.plotly_chart(create_star_plot(analyzed_df), use_container_width=True)

            progress_bar.progress(1.0)
            status_text.text("Analiz tamamlandÄ±!")

    except Exception as e:
        st.error(f"Bir hata oluÅŸtu: {str(e)}")
        st.session_state.analysis_started = False
